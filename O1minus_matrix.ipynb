{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller Notebook, which focuses only on the creation of cross correlation matrices, for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyhmc as phmc\n",
    "import scipy.linalg as la\n",
    "\n",
    "\n",
    "import struct\n",
    "\n",
    "Nt=16\n",
    "w, h = 3, Nt\n",
    "n_smear = 5\n",
    "n_op = 4\n",
    "n_meas =30000\n",
    "\n",
    "def E_mass(L,mass):\n",
    "    return np.arccosh(np.cosh(mass) + 1 -np.cos( 2*np.pi/L) )\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, np.transpose(a), rtol=rtol, atol=atol)\n",
    "\n",
    "def corr_th(x, a,b,c,d):\n",
    "    E= np.arccosh(2 - np.cos(2*np.pi/Nt))\n",
    "    return a * np.cosh((x-Nt/2)*b) + c*np.cosh((x-Nt/2)*d)\n",
    "\n",
    "\n",
    "\n",
    "def readfile(B_,Bphi_,B2_,BP2_,fn):\n",
    "    b_l = w * 8\n",
    "    ck = b_l*Nt*n_op\n",
    "    Sm_ck = ck*n_smear\n",
    "    with  open(fn,\"rb\" ) as f:\n",
    "        fileContent =f.read()\n",
    "        for n in range(n_meas):\n",
    "            for ns in range(n_smear):\n",
    "                for t in range(Nt):\n",
    "                    B_[n][ns][t]=struct.unpack(\"d\"*3, fileContent[(Sm_ck*n)+(ck*ns)+b_l*t:(Sm_ck*n)+(ck*ns)+(t+1)*b_l])\n",
    "                    B2_[n][ns][t]=struct.unpack(\"d\"*3, fileContent[(Sm_ck*n)+(ck*ns)+(b_l*Nt)+b_l*t:(Sm_ck*n)+(ck*ns)+(b_l*Nt)+(t+1)*b_l])\n",
    "                    Bphi_[n][ns][t]=struct.unpack(\"d\"*3, fileContent[(Sm_ck*n)+(ck*ns)+(b_l*Nt*2)+b_l*t:(Sm_ck*n)+(ck*ns)+(b_l*Nt*2)+(t+1)*b_l])\n",
    "                    BP2_[n][ns][t]=struct.unpack(\"d\"*3, fileContent[(Sm_ck*n)+(ck*ns)+(b_l*Nt*3)+b_l*t:(Sm_ck*n)+(ck*ns)+(b_l*Nt*3)+(t+1)*b_l])\n",
    "    print(\"File have been read\")\n",
    "\n",
    "\n",
    "    \n",
    "def cross_correlator(c_var):\n",
    "    O = [[[0 for y in range(h)]for z in range(n_smear) ]for n in range(n_meas) ]\n",
    "    O1 = [[[0 for y in range(h)]for z in range(n_smear) ]for n in range(n_meas) ]\n",
    "    O2 = [[[0 for y in range(h)]for z in range(n_smear) ]for n in range(n_meas) ]\n",
    "    O3 = [[[0 for y in range(h)]for z in range(n_smear) ]for n in range(n_meas) ]\n",
    "    O_sq = [[[0 for y in range(h)]for z in range(n_smear) ] for n in range(n_meas) ]\n",
    "    \n",
    "    \n",
    "    for n in range(n_meas):\n",
    "        for ns in range(n_smear):\n",
    "            for t in range(Nt):\n",
    "                for k in range(2):\n",
    "                    O[n][ns][t] += B[n][ns][t][k]/2\n",
    "                    O1[n][ns][t] += B1[n][ns][t][k]/2\n",
    "                    O3[n][ns][t] += B3[n][ns][t][k]/2\n",
    "                O_sq[n][ns][t] = O[n][ns][t]*O[n][ns][t] \n",
    "                for k in range(2):\n",
    "                    O2[n][ns][t] += (O_sq[n][ns][t]*B[n][ns][t][k])/2\n",
    "                    \n",
    "    \n",
    "    c_mat = [[0 for i in range(n_smear*n_op) ]for j in range(n_smear*n_op) ]\n",
    "    for n in range(n_meas):\n",
    "        for i in range(n_smear):\n",
    "            for j in range(n_smear):\n",
    "                for t in range(Nt):\n",
    "                    for t_pr in range(Nt):\n",
    "                            c_var[n][i][j][t]                     += (O [n][i][t_pr] * O [n][j][(t_pr+t)%Nt] + O [n][i][(t_pr+t)%Nt] * O [n][j][t_pr]) / 2\n",
    "                            c_var[n][i+n_smear][j+n_smear][t]     += (O1[n][i][t_pr] * O1[n][j][(t_pr+t)%Nt] + O1[n][i][(t_pr+t)%Nt] * O1[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+2*n_smear][j+2*n_smear][t] += (O2[n][i][t_pr] * O2[n][j][(t_pr+t)%Nt] + O2[n][i][(t_pr+t)%Nt] * O2[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+3*n_smear][j+3*n_smear][t] += (O3[n][i][t_pr] * O3[n][j][(t_pr+t)%Nt] + O3[n][i][(t_pr+t)%Nt] * O3[n][j][t_pr]) / 2\n",
    "                            c_var[n][i][j+n_smear][t]             += (O [n][i][t_pr] * O1[n][j][(t_pr+t)%Nt] + O [n][i][(t_pr+t)%Nt] * O1[n][j][t_pr]) / 2\n",
    "                            c_var[n][i][j+2*n_smear][t]           += (O [n][i][t_pr] * O2[n][j][(t_pr+t)%Nt] + O [n][i][(t_pr+t)%Nt] * O2[n][j][t_pr]) / 2\n",
    "                            c_var[n][i][j+3*n_smear][t]           += (O [n][i][t_pr] * O3[n][j][(t_pr+t)%Nt] + O [n][i][(t_pr+t)%Nt] * O3[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+n_smear][j][t]             += (O1[n][i][t_pr] * O [n][j][(t_pr+t)%Nt] + O1[n][i][(t_pr+t)%Nt] * O [n][j][t_pr]) / 2\n",
    "                            c_var[n][i+2*n_smear][j][t]           += (O2[n][i][t_pr] * O [n][j][(t_pr+t)%Nt] + O2[n][i][(t_pr+t)%Nt] * O [n][j][t_pr]) / 2\n",
    "                            c_var[n][i+3*n_smear][j][t]           += (O3[n][i][t_pr] * O [n][j][(t_pr+t)%Nt] + O3[n][i][(t_pr+t)%Nt] * O [n][j][t_pr]) / 2\n",
    "                            c_var[n][i+n_smear][j+2*n_smear][t]   += (O1[n][i][t_pr] * O2[n][j][(t_pr+t)%Nt] + O1[n][i][(t_pr+t)%Nt] * O2[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+n_smear][j+3*n_smear][t]   += (O1[n][i][t_pr] * O3[n][j][(t_pr+t)%Nt] + O1[n][i][(t_pr+t)%Nt] * O3[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+2*n_smear][j+3*n_smear][t] += (O2[n][i][t_pr] * O3[n][j][(t_pr+t)%Nt] + O2[n][i][(t_pr+t)%Nt] * O3[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+2*n_smear][j+n_smear][t]   += (O2[n][i][t_pr] * O1[n][j][(t_pr+t)%Nt] + O2[n][i][(t_pr+t)%Nt] * O1[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+3*n_smear][j+n_smear][t]   += (O3[n][i][t_pr] * O1[n][j][(t_pr+t)%Nt] + O3[n][i][(t_pr+t)%Nt] * O1[n][j][t_pr]) / 2\n",
    "                            c_var[n][i+3*n_smear][j+2*n_smear][t] += (O3[n][i][t_pr] * O2[n][j][(t_pr+t)%Nt] + O3[n][i][(t_pr+t)%Nt] * O2[n][j][t_pr]) / 2\n",
    "    print(\"cross correlators filled\")      \n",
    "    \n",
    "def cross_corr_stat(c_res,c,kappa):\n",
    "    #f = open('matrix.txt', 'w')\n",
    "    #f1 = open('matrix_err.txt', 'w')\n",
    "    c_mat = [[0 for i in range(n_smear*n_op) ]for j in range(n_smear*n_op) ]\n",
    "    c_mat_err = [[0 for i in range(n_smear*n_op) ]for j in range(n_smear*n_op) ]\n",
    "    c_res[0] = [[[0 for t in range(Nt)]for i in range(n_smear*n_op) ]for j in range(n_smear*n_op)  ]\n",
    "    #c_res[0] = np.mean(c,axis =0 )\n",
    "    for t in range(Nt):\n",
    "        for i in range(n_smear*n_op):\n",
    "            for j in range(n_smear*n_op):\n",
    "                #c_res[0][i][j][t] =0 \n",
    "                for n in range(n_meas):\n",
    "                    c_res[0][i][j][t] += (c[n][i][j][t]+c[n][j][i][t] )/(2*n_meas) \n",
    "    \n",
    "    #c_mat = [[0 for i in range(n_smear*n_op) ]for j in range(n_smear*n_op) ]\n",
    "    #for t in range(Nt):\n",
    "    #    for i in range(n_smear*n_op):\n",
    "    #        for j in range(n_smear*n_op):\n",
    "    #            c_mat[i][j] = c_res[0][i][j][t]\n",
    "    #    print('t= '+str(t)+str(check_symmetric(c_mat)))\n",
    "    #print(c_res[0][0][0])\n",
    "    c_res[1] = np.std(c,axis =0 )\n",
    "    c_res[2] = [[[0 for t in range(Nt)]for i in range(n_smear*n_op) ]for j in range(n_smear*n_op)  ]\n",
    "    for i in range(n_smear*n_op):\n",
    "        for j in range(n_smear*n_op):\n",
    "            for t in range(Nt):\n",
    "                vec = []\n",
    "                for n in range(n_meas):\n",
    "                    vec.append(float(c[n][i][j][t]))\n",
    "                c_res[2][i][j][t] = phmc.integrated_autocorr6(np.array(vec),6)\n",
    "                #c_res[2][ns][t] =1\n",
    "                #print(C_res[2][ns][t])\n",
    "                c_res[1][i][j][t] = c_res[1][i][j][t]* np.sqrt(c_res[2][i][j][t]/n_meas)\n",
    "    with open('cross/matrix_new_np_L%d_k%f.txt' %(Nt,kappa),'w')  as outfile:\n",
    "        with open('cross/matrix_new_np_L%d_k%f_err.txt'%(Nt,kappa),'w') as errfile:\n",
    "            for t in range(Nt):\n",
    "                for i in range(n_smear*n_op):\n",
    "                    for j in range(n_smear*n_op):\n",
    "                        c_mat[i][j]=float(c_res[0][i][j][t])\n",
    "                        c_mat_err[i][j]=float(c_res[1][i][j][t])\n",
    "                        \n",
    "                c_mat =np.array(c_mat)\n",
    "                c_mat_err =np.array(c_mat_err)\n",
    "        \n",
    "                np.savetxt(outfile ,c_mat,fmt='%.6f')\n",
    "                outfile.write('# New time slice\\n')\n",
    "                np.savetxt(errfile ,c_mat_err,fmt='%.6f')\n",
    "                errfile.write('# New time slice\\n')\n",
    "               \n",
    "    \n",
    "    print(\"Averages and uncertainties obtained\")\n",
    "  \n",
    "B = [[[[0 for x in range(w)] for y in range(h)]for z in range(n_smear) ] for n in range(n_meas) ]\n",
    "B1 = [[[[0 for x in range(w)] for y in range(h)]for z in range(n_smear) ]for n in range(n_meas) ]\n",
    "B2 = [[[[0 for x in range(w)] for y in range(h)]for z in range(n_smear) ] for n in range(n_meas) ]\n",
    "B3 = [[[[0 for x in range(w)] for y in range(h)]for z in range(n_smear) ] for n in range(n_meas)]\n",
    "\n",
    "C_var= [[[[0 for y in range(h)]for i in range(n_smear*n_op) ]for j in range(n_smear*n_op) ] for n in range(n_meas) ]\n",
    "C_var_res = [[[0 for j in range(n_smear) ]for i in range(n_smear) ] for y in range (3) ]\n",
    "\n",
    "\n",
    "def var_analysis_stat(kappa):\n",
    "    filename = \"O1minus_output_files_new/output_Nt%d_Nx%d_Ny%d_Nz%d_B4.000000_K%f_L1.000000_full.bin\" % (Nt,Nt,Nt,Nt,kappa)\n",
    "    readfile(B,B1,B2,B3,filename)                 \n",
    "    cross_correlator(C_var)      \n",
    "    cross_corr_stat(C_var_res,C_var,kappa)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File have been read\n",
      "cross correlators filled\n",
      "Averages and uncertainties obtained\n",
      "File have been read\n",
      "cross correlators filled\n",
      "Averages and uncertainties obtained\n"
     ]
    }
   ],
   "source": [
    "for k in range(2):\n",
    "    kappa = 0.55+ k*0.1\n",
    "    var_analysis_stat(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
